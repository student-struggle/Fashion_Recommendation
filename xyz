import os

import pickle

import numpy as np

from numpy.linalg import norm

from tqdm import tqdm

import tensorflow as tf

from tensorflow.keras.preprocessing import image

from tensorflow.keras.layers import GlobalMaxPooling2D

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input

 

# Local path to the folder containing the images

local_img_folder_path = r"C:\Users\student struggle\OneDrive\Desktop\New folder\Feshion_Design\images"

# Base URL for the images on GitHub

github_base_url =r"https://github.com/student-struggle/Fashion_Recommendation/tree/master/images"
 

# Function to create a mapping of local paths to GitHub URLs

def create_local_to_github_mapping(local_folder, github_base_url):

    filenames = []

    github_urls = []

    for file in os.listdir(local_folder):

        if file.endswith(('.png', '.jpg', '.jpeg')):

            local_path = os.path.join(local_folder, file)

            github_url = github_base_url + file

            filenames.append(local_path)

            github_urls.append(github_url)

    return filenames, github_urls

 

# Create the mapping

local_filenames, github_urls = create_local_to_github_mapping(local_img_folder_path, github_base_url)

 

# Save the GitHub URLs to a pickle file

with open('filenames.pkl', 'wb') as f:

    pickle.dump(github_urls, f)

 

# Load the ResNet50 model for feature extraction

model = ResNet50(weights="imagenet", include_top=False, input_shape=(224, 224, 3))

model.trainable = False

model = tf.keras.Sequential([model, GlobalMaxPooling2D()])

 

# Function to extract features from a local image file path

def extract_features_from_local(img_path, model):

    img = image.load_img(img_path, target_size=(224, 224))

    img_array = image.img_to_array(img)

    expanded_img_array = np.expand_dims(img_array, axis=0)

    preprocessed_img = preprocess_input(expanded_img_array)

    result = model.predict(preprocessed_img).flatten()

    normalized_result = result / norm(result)

    return normalized_result

 

# Extract features for each local image file

feature_list = []

for file in tqdm(local_filenames):

    features = extract_features_from_local(file, model)

    feature_list.append(features)

 

# Convert feature list to a numpy array and save to a pickle file

feature_array = np.array(feature_list)

pickle.dump(feature_array, open('feature_embedding.pkl', 'wb'))

 

print("Feature extraction and saving completed.")